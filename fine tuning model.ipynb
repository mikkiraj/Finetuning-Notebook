{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af5f5325",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /Users/mihikarajvanshi/anaconda3/lib/python3.10/site-packages (2.14.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in /Users/mihikarajvanshi/anaconda3/lib/python3.10/site-packages (from datasets) (0.16.4)\n",
      "Requirement already satisfied: multiprocess in /Users/mihikarajvanshi/anaconda3/lib/python3.10/site-packages (from datasets) (0.70.15)\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /Users/mihikarajvanshi/anaconda3/lib/python3.10/site-packages (from datasets) (0.3.7)\n",
      "Requirement already satisfied: xxhash in /Users/mihikarajvanshi/anaconda3/lib/python3.10/site-packages (from datasets) (3.3.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in /Users/mihikarajvanshi/anaconda3/lib/python3.10/site-packages (from datasets) (2.28.1)\n",
      "Requirement already satisfied: aiohttp in /Users/mihikarajvanshi/anaconda3/lib/python3.10/site-packages (from datasets) (3.8.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/mihikarajvanshi/anaconda3/lib/python3.10/site-packages (from datasets) (1.23.5)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in /Users/mihikarajvanshi/anaconda3/lib/python3.10/site-packages (from datasets) (2022.11.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/mihikarajvanshi/anaconda3/lib/python3.10/site-packages (from datasets) (6.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /Users/mihikarajvanshi/anaconda3/lib/python3.10/site-packages (from datasets) (4.64.1)\n",
      "Requirement already satisfied: pandas in /Users/mihikarajvanshi/anaconda3/lib/python3.10/site-packages (from datasets) (1.5.3)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /Users/mihikarajvanshi/anaconda3/lib/python3.10/site-packages (from datasets) (12.0.1)\n",
      "Requirement already satisfied: packaging in /Users/mihikarajvanshi/anaconda3/lib/python3.10/site-packages (from datasets) (22.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/mihikarajvanshi/anaconda3/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/mihikarajvanshi/anaconda3/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/mihikarajvanshi/anaconda3/lib/python3.10/site-packages (from aiohttp->datasets) (22.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/mihikarajvanshi/anaconda3/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /Users/mihikarajvanshi/anaconda3/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/mihikarajvanshi/anaconda3/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.3)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /Users/mihikarajvanshi/anaconda3/lib/python3.10/site-packages (from aiohttp->datasets) (2.0.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/mihikarajvanshi/anaconda3/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (4.4.0)\n",
      "Requirement already satisfied: filelock in /Users/mihikarajvanshi/anaconda3/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (3.9.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/mihikarajvanshi/anaconda3/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/mihikarajvanshi/anaconda3/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/mihikarajvanshi/anaconda3/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (1.26.14)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /Users/mihikarajvanshi/anaconda3/lib/python3.10/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/mihikarajvanshi/anaconda3/lib/python3.10/site-packages (from pandas->datasets) (2022.7)\n",
      "Requirement already satisfied: six>=1.5 in /Users/mihikarajvanshi/anaconda3/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f75a01cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mihikarajvanshi/anaconda3/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/var/folders/xy/j8x0tr_d115c1rx4md22hf400000gn/T/ipykernel_10598/270488574.py:3: FutureWarning: list_datasets is deprecated and will be removed in the next major version of datasets. Use 'huggingface_hub.list_datasets' instead.\n",
      "  datasets_list = list_datasets()\n"
     ]
    }
   ],
   "source": [
    ">>> from datasets import list_datasets\n",
    "from datasets import load_dataset\n",
    "dataset = load_dataset('imdb', '')\n",
    "train_data = dataset['train']\n",
    "test_data = dataset['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7dabf9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Convert train_data to a Pandas DataFrame\n",
    "train_df = pd.DataFrame(train_data)\n",
    "\n",
    "# Convert test_data to a Pandas DataFrame\n",
    "test_df = pd.DataFrame(test_data)\n",
    "\n",
    "# Save train_df to a CSV file\n",
    "train_df.to_csv('train_data.csv', index=False)\n",
    "\n",
    "# Save test_df to a CSV file\n",
    "test_df.to_csv('test_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2842b137",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /Users/mihikarajvanshi/anaconda3/lib/python3.10/site-packages (0.27.8)\n",
      "Requirement already satisfied: aiohttp in /Users/mihikarajvanshi/anaconda3/lib/python3.10/site-packages (from openai) (3.8.4)\n",
      "Requirement already satisfied: requests>=2.20 in /Users/mihikarajvanshi/anaconda3/lib/python3.10/site-packages (from openai) (2.28.1)\n",
      "Requirement already satisfied: tqdm in /Users/mihikarajvanshi/anaconda3/lib/python3.10/site-packages (from openai) (4.64.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/mihikarajvanshi/anaconda3/lib/python3.10/site-packages (from requests>=2.20->openai) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/mihikarajvanshi/anaconda3/lib/python3.10/site-packages (from requests>=2.20->openai) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/mihikarajvanshi/anaconda3/lib/python3.10/site-packages (from requests>=2.20->openai) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/mihikarajvanshi/anaconda3/lib/python3.10/site-packages (from requests>=2.20->openai) (3.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/mihikarajvanshi/anaconda3/lib/python3.10/site-packages (from aiohttp->openai) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/mihikarajvanshi/anaconda3/lib/python3.10/site-packages (from aiohttp->openai) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/mihikarajvanshi/anaconda3/lib/python3.10/site-packages (from aiohttp->openai) (22.1.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /Users/mihikarajvanshi/anaconda3/lib/python3.10/site-packages (from aiohttp->openai) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/mihikarajvanshi/anaconda3/lib/python3.10/site-packages (from aiohttp->openai) (1.9.2)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/mihikarajvanshi/anaconda3/lib/python3.10/site-packages (from aiohttp->openai) (6.0.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34183181",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing...\n",
      "\n",
      "- Based on your file extension, your file is formatted as a CSV file\n",
      "- Your file contains 25000 prompt-completion pairs\n",
      "- Based on your data it seems like you're trying to fine-tune a model for classification\n",
      "- For classification, we recommend you try one of the faster and cheaper models, such as `ada`\n",
      "- For classification, you can estimate the expected model performance by keeping a held out dataset, which is not used for training\n",
      "- There are 96 duplicated prompt-completion sets. These are rows: [168, 664, 701, 3070, 3591, 4215, 4216, 4217, 5104, 5551, 5552, 5553, 5554, 5555, 5556, 5557, 5558, 5920, 5949, 5950, 5951, 6353, 6537, 6538, 6539, 6540, 6541, 6542, 6543, 6544, 6877, 6984, 7121, 7177, 7585, 7586, 7587, 7588, 7868, 7869, 7870, 7871, 7872, 7873, 7874, 9392, 10006, 10172, 10274, 10275, 10276, 10277, 10278, 11416, 11592, 11593, 11864, 11959, 11960, 11961, 12001, 12231, 12309, 12310, 12383, 12384, 12385, 12468, 13263, 13424, 13447, 13880, 14142, 15644, 16812, 16821, 18158, 18624, 18804, 19363, 20259, 20738, 20897, 21125, 21740, 21741, 22161, 22162, 22163, 22164, 22165, 22166, 22676, 23942, 24513, 24960]\n",
      "- There are 3 examples that are very long. These are rows: [13756, 16948, 22551]\n",
      "For conditional generation, and for classification the examples shouldn't be longer than 2048 tokens.\n",
      "- Your data does not contain a common separator at the end of your prompts. Having a separator string appended to the end of the prompt makes it clearer to the fine-tuned model where the completion should begin. See https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset for more detail and examples. If you intend to do open-ended generation, then you should leave the prompts empty\n",
      "- The completion should start with a whitespace character (` `). This tends to produce better results due to the tokenization we use. See https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset for more details\n",
      "\n",
      "Based on the analysis we will perform the following actions:\n",
      "- [Necessary] Your format `CSV` will be converted to `JSONL`\n",
      "- [Recommended] Remove 96 duplicate rows [Y/n]: Y\n",
      "- [Recommended] Remove 3 long examples [Y/n]: Y\n",
      "The indices of the long examples has changed as a result of a previously applied recommendation.\n",
      "The 3 long examples to be dropped are now at the following indices: [13685, 16872, 22459]\n",
      "- [Recommended] Add a suffix separator ` ->` to all prompts [Y/n]: Y\n",
      "- [Recommended] Add a whitespace character to the beginning of the completion [Y/n]: Y\n",
      "- [Recommended] Would you like to split into training and validation set? [Y/n]: Y\n",
      "\n",
      "\n",
      "Your data will be written to a new JSONL file. Proceed [Y/n]: Y\n",
      "\n",
      "Wrote modified files to `updated_prepared_train (1).jsonl` and `updated_prepared_valid (1).jsonl`\n",
      "Feel free to take a look!\n",
      "\n",
      "Now use that file when fine-tuning:\n",
      "> openai api fine_tunes.create -t \"updated_prepared_train (1).jsonl\" -v \"updated_prepared_valid (1).jsonl\" --compute_classification_metrics --classification_positive_class \" positive\"\n",
      "\n",
      "After youâ€™ve fine-tuned a model, remember that your prompt has to end with the indicator string ` ->` for the model to start generating completions, rather than continuing with the prompt. Make sure to include `stop=[\"tive\"]` so that the generated texts ends at the expected place.\n",
      "Once your model starts training, it'll approximately take 10.0 hours to train a `curie` model, and less for `ada` and `babbage`. Queue will approximately take half an hour per job ahead of you.\n"
     ]
    }
   ],
   "source": [
    "file_path = '/Users/mihikarajvanshi/Desktop/cs projects/yash_projects/train_data.csv'\n",
    "\n",
    "train_df.head()\n",
    "train_df.loc[train_df[\"label\"] == 0, \"label\"] = \"negative\"\n",
    "train_df.loc[train_df[\"label\"] == 1, \"label\"] = \"positive\"\n",
    "\n",
    "updated = train_df.rename(columns={\"text\": \"prompt\", \"label\": \"completion\"})\n",
    "\n",
    "updated.to_csv('updated.csv', index=False)\n",
    "!openai tools fine_tunes.prepare_data -f 'updated.csv' -q\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02d26d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import openai\n",
    "\n",
    "# !openai api fine_tunes.create -t \"updated_prepared_train.jsonl\" -v \"updated_prepared_train.jsonl\" -m ada --suffix \"imdb model\"\n",
    "# openai api fine_tunes.create -t test.jsonl -m ada --suffix \"imdb model\"\n",
    "!openai api fine_tunes.create -t \"updated_prepared_train (1).jsonl\" -v \"updated_prepared_valid (1).jsonl\" --compute_classification_metrics --classification_positive_class \" positive\" -m ada --suffix 'imdb'\n",
    "\n",
    "print('done')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
